[
    {
        "title": "Differential Transformer",
        "date": "2025-01-11",
        "description": "A deep dive into Differential Attention and how it reduces noise allocation in transformer architectures by subtracting two softmax attention maps.",
        "badge": "PAPER REVIEW",
        "category": "Attention",
        "link": "/laundryroom/notes/differential_transformer.html"
    },
    {
        "title": "Hierarchial Reasoning Models",
        "date": "<built-in method date of datetime.datetime object at 0x000002507E4076F0>",
        "description": "A walkthrough of our MCTS implementation. We discuss distributed training challenges and compare performance metrics against DeepMind's reported figures.",
        "link": "notes/hierarchial_reasoning_models.html"
    },
    {
        "title": "Attention sinks",
        "date": "2025-12-23",
        "description": "Empty",
        "link": "notes/attention_sinks.html"
    },
    {
        "title": "The Platonic Representation Hypothesis",
        "date": "2025-12-23",
        "description": "Empty",
        "link": "notes/the_platonic_representation_hypothesis.html"
    },
    {
        "title": "Why DPO is a misspecified estimator and how to fix it",
        "date": "2025-12-25",
        "description": "DPO is a very weird algorithm",
        "link": "notes/why_dpo_is_a_misspecified_estimator_and_how_to_fix_it.html"
    },
    {
        "title": "The Disagreement Problem in Explainable Machine LearningA Practitioner’s Perspective",
        "date": "2025-12-25",
        "description": "Disagreements in explainable ML",
        "link": "notes/the_disagreement_problem_in_explainable_machine_learninga_practitioner’s_perspective.html"
    },
    {
        "title": "A Graph Signal Processing Framework for Hallucination Detection in Large Language Models",
        "date": "2025-12-27",
        "description": "A spectral analysis framework to analyse hallucinations in LLMs",
        "link": "notes/graph_signal_processing.html"
    }
]